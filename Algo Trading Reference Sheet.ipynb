{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21719bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is William Franks reference sheet for Algo Trading at Northeastern\n",
    "Below will include relevant functions and operations needed for the class\n",
    "\n",
    "The information will be sorted by cells with the title at the top\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bb7875a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import numpy as np\n",
    "import statistics\n",
    "import requests\n",
    "import csv\n",
    "\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy import stats\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1d0fae75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(-0.17474690099903256)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean, Variance, Skew, Kurtosis\n",
    "\n",
    "data = [1, 5, -3, 8, 2]\n",
    "data_df = pd.DataFrame()\n",
    "data_df['Data'] = data\n",
    "\n",
    "np.mean(data) # mean\n",
    "\n",
    "statistics.variance(data) # Sample Variance\n",
    "statistics.pvariance(data) # Population Variance\n",
    "\n",
    "skew(data, bias=False) # Scipy Skew, bias=False means it IS corrected for bias\n",
    "data_df['Data'].skew() # Pandas Skew\n",
    "\n",
    "kurtosis(data, bias=False, fisher=False) # Scipy Kurtosis, fisher=True for Exkurtosis\n",
    "data_df['Data'].kurtosis() # Pandas Kurtosis, defaults to Exkurtosis. 3 less than above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8e6df723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.08550148560121865"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Covariance and Correlation\n",
    "\n",
    "x = [-1, 5, -7, 4, -10]\n",
    "y = [2, -1, 14, 8, -2]\n",
    "df = pd.DataFrame()\n",
    "df['x'] = x\n",
    "df['y'] = y\n",
    "\n",
    "np.cov(x, y, ddof=1) # NumPy Covariance matrix (Sample Cov, ddof=1)\n",
    "np.cov(x, y, ddof=1)[0, 1] # NumPy Covariance\n",
    "df['x'].cov(df['y']) # Pandas Covariance (Sample Cov, n-1)\n",
    "statistics.covariance(x, y) # Stats Cov\n",
    "\n",
    "np.corrcoef(x, y) # NumPy correlation matrix\n",
    "np.corrcoef(x, y)[0, 1] # NumPy correlation\n",
    "df['x'].corr(df['y']) # Pandas correlation\n",
    "statistics.correlation(x, y) # Stats Cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f691c2c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.03442302239088593)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hypothesis Testing\n",
    "# For all the questions, different = \"Statistically Different\"\n",
    "\n",
    "np.random.seed(42) # Just random data for us to use\n",
    "x = np.random.normal(0.05, 0.15, 100) # mean, stddev, n\n",
    "y = np.random.normal(0.02, 0.20, 100)\n",
    "\n",
    "# Is the mean of x different from 0, SciPy 1 sample T\n",
    "t_stat, p_val_1 = stats.ttest_1samp(x, 0) \n",
    "\n",
    "# Is the variance of x different from 0.0225 (0.15**2), SciPy 1 sample var\n",
    "n = len(x)\n",
    "target_var = 0.15 ** 2\n",
    "chi_sq = (n - 1) * np.var(x, ddof=1) / target_var\n",
    "p_val_2 = 2 * min(stats.chi2.cdf(chi_sq, n-1), stats.chi2.sf(chi_sq, n-1))\n",
    "\n",
    "# Is mean(x) different to mean(y), SciPy 2 sample t\n",
    "_, p_val_3 = stats.ttest_ind(x, y, equal_var=False) # False means Welch's T\n",
    "\n",
    "# Is Var(x) different to Var(y), Scipy 2 sample T\n",
    "_, p_val_4 = stats.levene(x, y)\n",
    "\n",
    "# Is x normally distributed? SciPy, Jarque Bera Test\n",
    "_, p_val_5 = stats.jarque_bera(x)\n",
    "\n",
    "# Hand Calculation t stat (is mean different than 2%)\n",
    "t_stat = (x.mean() - 0.02) / (x.std() / (len(x) ** 0.5)) # (xbar - null) / (stddev / (sqrt(n)))\n",
    "deg_freedom = len(x) - 1\n",
    "p_value = 2 * (1 - stats.t.cdf(abs(t_stat), df=deg_freedom))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3443eb5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True],\n",
       "       [ True,  True]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix Operations\n",
    "\n",
    "A = np.array(\n",
    "    [[4, 5],\n",
    "     [5, 9]]\n",
    "     )\n",
    "\n",
    "A.T # Transpose of Matrix A\n",
    "np.linalg.inv(A) # Inverse of Matrix A\n",
    "value, vector = np.linalg.eig(A) # Eiganvalue and Eigenvector of Matrix A\n",
    "np.linalg.cholesky(A) # Cholesky, Symmetric Matrices only\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ece2d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "dict_keys(['Meta Data', 'Time Series (Daily)'])\n"
     ]
    }
   ],
   "source": [
    "# Alpha Vantage Processing\n",
    "\n",
    "key='&apikey=ZKMMTO1ATDBLXH2K' # API Key\n",
    "ticker='&symbol=IBM' # Ticker\n",
    "endpoint='function=TIME_SERIES_DAILY_ADJUSTED' # Called 'function', the dataset we want\n",
    "size='&outputsize=compact'\n",
    "web='https://www.alphavantage.co/query?'\n",
    "url =web+endpoint+ticker+size+key\n",
    "\n",
    "r = requests.get(url)\n",
    "print(r.status_code) # 200 good, 400 bad\n",
    "data = r.json()\n",
    "\n",
    "print(data.keys()) #printing the keys\n",
    "meta = data['Meta Data']\n",
    "time_series_data = data['Time Series (Daily)']\n",
    "\n",
    "ts_df = pd.DataFrame.from_dict(time_series_data, orient='index').reset_index().rename(columns={'index': 'Date'})\n",
    "clean_cols_dict = {'1. open': 'Open', '2. high': 'High', '3. low': 'Low', '4. close': 'Close', # Dictionary to convert the names of the columns\n",
    "            '5. adjusted close': 'Adj Close', '6. volume': 'Volume', '7. dividend amount': 'Dividend', '8. split coefficient': 'Split Coef'}\n",
    "\n",
    "clean=[] # This is how you do it with standard Python\n",
    "for date in time_series_data.keys():\n",
    "    # print (r1[date])\n",
    "    clean.append([date, meta['2. Symbol'], time_series_data[date]['4. close']]) #stacking prices\n",
    "\n",
    "\n",
    "ts_np = ts_df.to_numpy() # How to convert a df to a 2d numpy matrix\n",
    "\n",
    "np.savetxt(\"IBM TS Price.csv\", ts_np, delimiter=\",\", fmt=\"%s\") # Saves to the folder you are working in\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd190973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas Time Series\n",
    "\n",
    "df['Price MAVG'] = df['Price'].rolling(window=3).mean() # Where 3 is the amount of values we look back inclusive of current value\n",
    "\n",
    "# The log return of today - yesterday, provides a value for every row in df besides first row, change shift to change the interval\n",
    "ts_df['Monthly Log Return'] = np.log(ts_df['Adj Close'] / ts_df['Adj Close'].shift(1)) # log(a) - log(b) = log(a/b)\n",
    "\n",
    "# 2.5% percentile (Bottom 1/25 of values)\n",
    "p2_5 = ts_df['Monthly Log Return'].quantile(0.025)\n",
    "\n",
    "# Shifting values down\n",
    "ts_df['Sell'] = ts_df['Buy'].shift(1) # The sell column is now the buy column shifted down by 1 row\n",
    "\n",
    "# Get a df with just the last day of every month, useful when last trading day isn't month end\n",
    "monthly_df = ts_df.set_index('Date')\n",
    "monthly_prices = monthly_df.groupby(pd.Grouper(freq='ME')).tail(1)['Adj Close']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
